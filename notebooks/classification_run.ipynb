{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hector Auvinen\\Documents\\GitHub\\adapter_experiments\\adapter_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0,project_root)\n",
    "\n",
    "from src.data_handling.load_data import *\n",
    "from src.data_handling.preprocessing import *\n",
    "from src.models.model_setup import *\n",
    "from src.trainer.training import *\n",
    "from src.trainer.file_utils import *\n",
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "set_seed(seed_value)\n",
    "# supports tasks:\n",
    "# cb\n",
    "# rte\n",
    "# sick\n",
    "# mrpc\n",
    "# boolq\n",
    "# csqa ?????????? or mc?\n",
    "# argument\n",
    "# scitail\n",
    "# imdb\n",
    "# sst2\n",
    "# qqp\n",
    "# mnli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"scitail\"\n",
    "model_name = \"bert-base-uncased\"\n",
    "output_dir = \"C:/Users/Hector Auvinen/Desktop/eval_results\"\n",
    "#logger = logging.getLogger(__name__)\n",
    "#logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using bert tokenizer\n",
      "getting encoding:\n",
      "<function encode_scitail at 0x000002C001F6E550>\n"
     ]
    }
   ],
   "source": [
    "data = load_hf_dataset(task,debug=False)\n",
    "\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "encode = get_encoding(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/23097 [00:00<?, ? examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|▍         | 1000/23097 [00:01<00:36, 601.84 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map: 100%|██████████| 23097/23097 [00:29<00:00, 786.54 examples/s]\n",
      "Map: 100%|██████████| 2126/2126 [00:02<00:00, 843.38 examples/s]\n",
      "Map: 100%|██████████| 1304/1304 [00:01<00:00, 813.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped\n",
      "{'train': ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'], 'test': ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'], 'validation': ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#def preprocess_dataset(dataset,encoding_func,tokenizer):\n",
    "dataset = preprocess_dataset(data,encode,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#id2label = {id: label for (id,label) in enumerate(dataset[\"train\"].features[\"labels\"].names)}\n",
    "#num_labels = len(id2label)\n",
    "num_labels = get_label_count(dataset)\n",
    "print(\"labels\",num_labels)\n",
    "model = setup_model(model_name,num_labels,dataset)\n",
    "\n",
    "adapter_config = adapters.BnConfig(\n",
    "                          output_adapter=True,\n",
    "                          mh_adapter=False,\n",
    "                          reduction_factor=2,\n",
    "                          non_linearity=\"relu\")\n",
    "\n",
    "model = add_clf_adapter(task_name=task,model=model,num_labels=num_labels,adapter_config=adapter_config)\n",
    "\n",
    "default_args = TrainingParameters()\n",
    "default_args.lr_scheduler_type = \"linear\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  0%|          | 50/86640 [00:45<8:09:11,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5120983719825745, 'eval_accuracy': 0.7576687116564417, 'eval_runtime': 26.097, 'eval_samples_per_second': 49.967, 'eval_steps_per_second': 6.246, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/86640 [01:01<7:49:31,  3.07it/s] \n",
      "  0%|          | 100/86640 [01:27<7:49:31,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.482826828956604, 'eval_accuracy': 0.7507668711656442, 'eval_runtime': 26.8769, 'eval_samples_per_second': 48.517, 'eval_steps_per_second': 6.065, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 150/86640 [02:12<7:49:15,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.407736599445343, 'eval_accuracy': 0.8205521472392638, 'eval_runtime': 27.6917, 'eval_samples_per_second': 47.09, 'eval_steps_per_second': 5.886, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200/86640 [02:29<7:43:01,  3.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5546, 'learning_rate': 9.976915974145891e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  0%|          | 200/86640 [02:57<7:43:01,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36100077629089355, 'eval_accuracy': 0.8496932515337423, 'eval_runtime': 28.7014, 'eval_samples_per_second': 45.433, 'eval_steps_per_second': 5.679, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 250/86640 [03:43<9:12:41,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36655500531196594, 'eval_accuracy': 0.8504601226993865, 'eval_runtime': 28.0162, 'eval_samples_per_second': 46.545, 'eval_steps_per_second': 5.818, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 300/86640 [04:28<8:00:13,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3831276595592499, 'eval_accuracy': 0.8328220858895705, 'eval_runtime': 27.7914, 'eval_samples_per_second': 46.921, 'eval_steps_per_second': 5.865, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 350/86640 [05:13<8:13:31,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3124072253704071, 'eval_accuracy': 0.8711656441717791, 'eval_runtime': 28.0155, 'eval_samples_per_second': 46.546, 'eval_steps_per_second': 5.818, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 400/86640 [05:30<8:39:21,  2.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4675, 'learning_rate': 9.953831948291783e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  0%|          | 400/86640 [05:57<8:39:21,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4579084813594818, 'eval_accuracy': 0.8029141104294478, 'eval_runtime': 26.6335, 'eval_samples_per_second': 48.961, 'eval_steps_per_second': 6.12, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 450/86640 [06:41<8:00:06,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3183535635471344, 'eval_accuracy': 0.8573619631901841, 'eval_runtime': 27.2307, 'eval_samples_per_second': 47.887, 'eval_steps_per_second': 5.986, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 500/86640 [07:27<8:23:01,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28294530510902405, 'eval_accuracy': 0.8757668711656442, 'eval_runtime': 28.7131, 'eval_samples_per_second': 45.415, 'eval_steps_per_second': 5.677, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 550/86640 [08:13<8:04:11,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3734060525894165, 'eval_accuracy': 0.8404907975460123, 'eval_runtime': 28.8571, 'eval_samples_per_second': 45.188, 'eval_steps_per_second': 5.649, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 600/86640 [08:30<8:23:48,  2.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3736, 'learning_rate': 9.930747922437674e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  1%|          | 600/86640 [09:00<8:23:48,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29867643117904663, 'eval_accuracy': 0.870398773006135, 'eval_runtime': 29.1901, 'eval_samples_per_second': 44.673, 'eval_steps_per_second': 5.584, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 650/86640 [09:45<8:40:19,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3124051094055176, 'eval_accuracy': 0.8734662576687117, 'eval_runtime': 27.8346, 'eval_samples_per_second': 46.848, 'eval_steps_per_second': 5.856, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 650/86640 [09:46<21:32:15,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 586.0818, 'train_samples_per_second': 1182.275, 'train_steps_per_second': 147.829, 'train_loss': 0.4591100810124324, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=650, training_loss=0.4591100810124324, metrics={'train_runtime': 586.0818, 'train_samples_per_second': 1182.275, 'train_steps_per_second': 147.829, 'train_loss': 0.4591100810124324, 'epoch': 0.23})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_args = get_training_arguments(default_args)\n",
    "\n",
    "trainer = get_trainer(train_args,dataset,model,early_stopping=3)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:27<00:00,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing eval results\n",
      "{'eval_loss': 0.6164497137069702, 'eval_accuracy': 0.6672782874617736, 'eval_runtime': 46.1558, 'eval_samples_per_second': 70.847, 'eval_steps_per_second': 8.861, 'epoch': 0.64}\n"
     ]
    }
   ],
   "source": [
    "write_eval_results(eval_results,output_dir,task,trainer,adapter_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    train_args = {\"label_names\":[\"labels\"],\\n    \"evaluation_strategy\":\"steps\",\\n    \"learning_rate\":1e-4,\\n    \"num_train_epochs\":1,\\n    \"per_device_train_batch_size\":8,\\n    \"per_device_eval_batch_size\":8,\\n    \"eval_steps\":50,\\n    \"logging_steps\":200,\\n    \"output_dir\":\"/eval_results\",\\n    \"overwrite_output_dir\":True,\\n    \"remove_unused_columns\":False,\\n    \"lr_scheduler_type\":\\'linear\\',\\n    \"load_best_model_at_end\":True,\\n    \"metric_for_best_model\" : \"accuracy\",\\n    \"early_stopping_patience\":3,\\n    \"save_total_limit\":5\\n}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for attr_name, attr_value in vars(default_args).items():\n",
    "    print(f\"{attr_name}: {attr_value}\")\"\"\"\n",
    "\"\"\"\n",
    "    train_args = {\"label_names\":[\"labels\"],\n",
    "    \"evaluation_strategy\":\"steps\",\n",
    "    \"learning_rate\":1e-4,\n",
    "    \"num_train_epochs\":1,\n",
    "    \"per_device_train_batch_size\":8,\n",
    "    \"per_device_eval_batch_size\":8,\n",
    "    \"eval_steps\":50,\n",
    "    \"logging_steps\":200,\n",
    "    \"output_dir\":\"/eval_results\",\n",
    "    \"overwrite_output_dir\":True,\n",
    "    \"remove_unused_columns\":False,\n",
    "    \"lr_scheduler_type\":'linear',\n",
    "    \"load_best_model_at_end\":True,\n",
    "    \"metric_for_best_model\" : \"accuracy\",\n",
    "    \"early_stopping_patience\":3,\n",
    "    \"save_total_limit\":5\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c9858cbf84a5da59b0eda444a3a9e74ff602edf6c20b71c559d82c1d8891e69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
