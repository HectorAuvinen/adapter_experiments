{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hector Auvinen\\Documents\\GitHub\\adapter_experiments\\adapter_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import json\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0,project_root)\n",
    "\n",
    "from src.data_handling.load_data import *\n",
    "from src.data_handling.preprocessing import *\n",
    "from src.models.model_setup import *\n",
    "from src.trainer.training import *\n",
    "from src.trainer.file_utils import *\n",
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_adapter = config[\"output_adapter\"]\\nmh_adapter = config[\"mh_adapter\"]\\nreduction_factor = config[\"reduction_factor\"]\\nnon_linearity = config[\"non_linearity\"]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value = 42\n",
    "set_seed(seed_value)\n",
    "# supports tasks:\n",
    "# cb\n",
    "# rte\n",
    "# sick\n",
    "# mrpc\n",
    "# boolq\n",
    "# csqa ?????????? or mc?\n",
    "# argument\n",
    "# scitail\n",
    "# imdb\n",
    "# sst2\n",
    "# qqp\n",
    "# mnli\n",
    "\n",
    "#tasks = [\"cb\",\"rte\",\"sick\",\"mrpc\",\"boolq\",\"argument\",\"scitail\",\"imdb\",\"sst2\",\"qqp\",\"mnli\"]\n",
    "tasks = [\"imdb\",\"sst2\",\"qqp\",\"mnli\"]\n",
    "# task = \"scitail\"\n",
    "model_name = \"bert-base-uncased\"\n",
    "output_path = \"C:/Users/Hector Auvinen/Desktop/eval_results/test_root_for_evals\"\n",
    "adapter_conf_path = \"../src/configs/adapter_configs.json\"\n",
    "\n",
    "\"\"\"output_adapter = config[\"output_adapter\"]\n",
    "mh_adapter = config[\"mh_adapter\"]\n",
    "reduction_factor = config[\"reduction_factor\"]\n",
    "non_linearity = config[\"non_linearity\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_adapter_redf_2': {'output_adapter': True,\n",
       "  'mh_adapter': False,\n",
       "  'reduction_factor': 2,\n",
       "  'non_linearity': 'relu'},\n",
       " 'output_adapter_redf_16': {'output_adapter': True,\n",
       "  'mh_adapter': False,\n",
       "  'reduction_factor': 16,\n",
       "  'non_linearity': 'relu'},\n",
       " 'output_adapter_redf_64': {'output_adapter': True,\n",
       "  'mh_adapter': False,\n",
       "  'reduction_factor': 64,\n",
       "  'non_linearity': 'relu'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOVE THIS TO MODULE\n",
    "with open(adapter_conf_path, \"r\") as json_file:\n",
    "    adapter_configs = json.load(json_file)\n",
    "adapter_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_adapter_redf_2 {'output_adapter': True, 'mh_adapter': False, 'reduction_factor': 2, 'non_linearity': 'relu'}\n",
      "Folder 'C:/Users/Hector Auvinen/Desktop/eval_results/test_root_for_evals\\output_adapter_redf_2' already exists.\n",
      "**********************************RUNNING CONFIG output_adapter_redf_2*****************************\n",
      "CONFIG {'output_adapter': True, 'mh_adapter': False, 'reduction_factor': 2, 'non_linearity': 'relu'}\n",
      "**********************************RUNNING TASK imdb*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 7.81k/7.81k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 21.0M/21.0M [00:02<00:00, 8.97MB/s]\n",
      "Downloading data: 100%|██████████| 20.5M/20.5M [00:02<00:00, 8.40MB/s]\n",
      "Downloading data: 100%|██████████| 42.0M/42.0M [00:04<00:00, 9.86MB/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 153280.86 examples/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 203807.63 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 215219.22 examples/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**********************************RUNNING TASK \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*****************************\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# load dataset\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_hf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# get tokenizer (bert)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m get_tokenizer(model_name)\n",
      "File \u001b[1;32mc:\\Users\\Hector Auvinen\\Documents\\GitHub\\adapter_experiments\\src\\data_handling\\load_data.py:43\u001b[0m, in \u001b[0;36mload_hf_dataset\u001b[1;34m(task_name, debug)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimdb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     42\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_dataset(task_name,split\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 43\u001b[0m     dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinogrande\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     45\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_dataset(task_name,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinogrande_xl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for name,config in adapter_configs.items():\n",
    "    print(name,config)\n",
    "    output_dir = os.path.join(output_path,name)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        # If the folder doesn't exist, create it\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Folder '{output_dir}' created.\")\n",
    "    else:\n",
    "        print(f\"Folder '{output_dir}' already exists.\")\n",
    "    \n",
    "    print(f\"**********************************RUNNING CONFIG {name}*****************************\")\n",
    "    print(\"CONFIG\",config)\n",
    "    for task in tasks:\n",
    "        print(f\"**********************************RUNNING TASK {task}*****************************\")\n",
    "        # load dataset\n",
    "        data = load_hf_dataset(task,debug=False)\n",
    "        # get tokenizer (bert)\n",
    "        tokenizer = get_tokenizer(model_name)\n",
    "        # get encoding method for particular task\n",
    "        encode = get_encoding(task)\n",
    "        # apply encoding\n",
    "        dataset = preprocess_dataset(data,encode,tokenizer)\n",
    "        # get label count\n",
    "        num_labels = get_label_count(dataset)\n",
    "        # set up model (head with num labels)\n",
    "        model = setup_model(model_name,num_labels,dataset)\n",
    "        \n",
    "        # set up adapter config\n",
    "        adapter_config = adapters.BnConfig(\n",
    "                                output_adapter=config[\"output_adapter\"],\n",
    "                                mh_adapter=config[\"mh_adapter\"],\n",
    "                                reduction_factor=config[\"reduction_factor\"],\n",
    "                                non_linearity=config[\"non_linearity\"])\n",
    "\n",
    "        # add adapter\n",
    "        model = add_clf_adapter(task_name=task,model=model,num_labels=num_labels,adapter_config=adapter_config)\n",
    "        \n",
    "        # set up training args\n",
    "        final_output = os.path.join(output_dir,task)\n",
    "        default_args = TrainingParameters(output_dir=final_output,per_device_train_batch_size=1)\n",
    "        default_args.lr_scheduler_type = \"linear\"\n",
    "        train_args = get_training_arguments(default_args)\n",
    "        \n",
    "        # set up trainer\n",
    "        trainer = get_trainer(train_args,dataset,model,early_stopping=3)\n",
    "        # train\n",
    "        trainer.train()\n",
    "        \n",
    "        # evaluate and write results to file\n",
    "        eval_results = trainer.evaluate()\n",
    "        write_eval_results(eval_results,output_dir,task,trainer,adapter_config)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 649k/649k [00:00<00:00, 1.66MB/s]\n",
      "Downloading data: 100%|██████████| 75.7k/75.7k [00:00<00:00, 359kB/s]\n",
      "Downloading data: 100%|██████████| 308k/308k [00:00<00:00, 1.35MB/s]\n",
      "Generating train split: 100%|██████████| 3668/3668 [00:00<00:00, 353070.80 examples/s]\n",
      "Generating validation split: 100%|██████████| 408/408 [00:00<00:00, 101637.82 examples/s]\n",
      "Generating test split: 100%|██████████| 1725/1725 [00:00<00:00, 216201.24 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using bert tokenizer\n",
      "getting encoding:\n",
      "<function encode_mrpc at 0x000002E00F811550>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3668/3668 [00:06<00:00, 590.85 examples/s]\n",
      "Map: 100%|██████████| 408/408 [00:00<00:00, 577.79 examples/s]\n",
      "Map: 100%|██████████| 1725/1725 [00:02<00:00, 599.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped\n",
      "{'train': ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'], 'validation': ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'], 'test': ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask']}\n",
      "labels 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 29/13770 [00:12<1:41:40,  2.25it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m train_args \u001b[38;5;241m=\u001b[39m get_training_arguments(default_args)\n\u001b[0;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m get_trainer(train_args,dataset,model,early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m     36\u001b[0m write_eval_results(eval_results,output_dir,task,trainer,adapter_config)\n",
      "File \u001b[1;32mc:\\Users\\Hector Auvinen\\Documents\\GitHub\\adapter_experiments\\adapter_env\\lib\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hector Auvinen\\Documents\\GitHub\\adapter_experiments\\adapter_env\\lib\\site-packages\\transformers\\trainer.py:1862\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m   1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m-> 1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1866\u001b[0m ):\n\u001b[0;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### full run:\n",
    "####### MOVE THIS TO A .PY SCRIPT. ONLY HERE FOR A TEST RUN\n",
    "task = \"mrpc\"\n",
    "data = load_hf_dataset(task,debug=False)\n",
    "\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "encode = get_encoding(task)\n",
    "\n",
    "dataset = preprocess_dataset(data,encode,tokenizer)\n",
    "\n",
    "\n",
    "num_labels = get_label_count(dataset)\n",
    "print(\"labels\",num_labels)\n",
    "model = setup_model(model_name,num_labels,dataset)\n",
    "\n",
    "adapter_config = adapters.BnConfig(\n",
    "                          output_adapter=True,\n",
    "                          mh_adapter=False,\n",
    "                          reduction_factor=2,\n",
    "                          non_linearity=\"relu\")\n",
    "\n",
    "model = add_clf_adapter(task_name=task,model=model,num_labels=num_labels,adapter_config=adapter_config)\n",
    "\n",
    "default_args = TrainingParameters()\n",
    "default_args.lr_scheduler_type = \"linear\"\n",
    "\n",
    "train_args = get_training_arguments(default_args)\n",
    "\n",
    "trainer = get_trainer(train_args,dataset,model,early_stopping=3)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "write_eval_results(eval_results,output_dir,task,trainer,adapter_config)\n",
    "##### full run ends. MOVE THIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using bert tokenizer\n",
      "getting encoding:\n",
      "<function encode_scitail at 0x000002C001F6E550>\n"
     ]
    }
   ],
   "source": [
    "data = load_hf_dataset(task,debug=False)\n",
    "\n",
    "tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "encode = get_encoding(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/23097 [00:00<?, ? examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|▍         | 1000/23097 [00:01<00:36, 601.84 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map: 100%|██████████| 23097/23097 [00:29<00:00, 786.54 examples/s]\n",
      "Map: 100%|██████████| 2126/2126 [00:02<00:00, 843.38 examples/s]\n",
      "Map: 100%|██████████| 1304/1304 [00:01<00:00, 813.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped\n",
      "{'train': ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'], 'test': ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'], 'validation': ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_dataset(data,encode,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertAdapterModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['heads.default.3.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#id2label = {id: label for (id,label) in enumerate(dataset[\"train\"].features[\"labels\"].names)}\n",
    "#num_labels = len(id2label)\n",
    "num_labels = get_label_count(dataset)\n",
    "print(\"labels\",num_labels)\n",
    "model = setup_model(model_name,num_labels,dataset)\n",
    "\n",
    "adapter_config = adapters.BnConfig(\n",
    "                          output_adapter=True,\n",
    "                          mh_adapter=False,\n",
    "                          reduction_factor=2,\n",
    "                          non_linearity=\"relu\")\n",
    "\n",
    "model = add_clf_adapter(task_name=task,model=model,num_labels=num_labels,adapter_config=adapter_config)\n",
    "\n",
    "default_args = TrainingParameters()\n",
    "default_args.lr_scheduler_type = \"linear\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  0%|          | 50/86640 [00:45<8:09:11,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5120983719825745, 'eval_accuracy': 0.7576687116564417, 'eval_runtime': 26.097, 'eval_samples_per_second': 49.967, 'eval_steps_per_second': 6.246, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/86640 [01:01<7:49:31,  3.07it/s] \n",
      "  0%|          | 100/86640 [01:27<7:49:31,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.482826828956604, 'eval_accuracy': 0.7507668711656442, 'eval_runtime': 26.8769, 'eval_samples_per_second': 48.517, 'eval_steps_per_second': 6.065, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 150/86640 [02:12<7:49:15,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.407736599445343, 'eval_accuracy': 0.8205521472392638, 'eval_runtime': 27.6917, 'eval_samples_per_second': 47.09, 'eval_steps_per_second': 5.886, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 200/86640 [02:29<7:43:01,  3.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5546, 'learning_rate': 9.976915974145891e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  0%|          | 200/86640 [02:57<7:43:01,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36100077629089355, 'eval_accuracy': 0.8496932515337423, 'eval_runtime': 28.7014, 'eval_samples_per_second': 45.433, 'eval_steps_per_second': 5.679, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 250/86640 [03:43<9:12:41,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36655500531196594, 'eval_accuracy': 0.8504601226993865, 'eval_runtime': 28.0162, 'eval_samples_per_second': 46.545, 'eval_steps_per_second': 5.818, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 300/86640 [04:28<8:00:13,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3831276595592499, 'eval_accuracy': 0.8328220858895705, 'eval_runtime': 27.7914, 'eval_samples_per_second': 46.921, 'eval_steps_per_second': 5.865, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  0%|          | 350/86640 [05:13<8:13:31,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3124072253704071, 'eval_accuracy': 0.8711656441717791, 'eval_runtime': 28.0155, 'eval_samples_per_second': 46.546, 'eval_steps_per_second': 5.818, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 400/86640 [05:30<8:39:21,  2.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4675, 'learning_rate': 9.953831948291783e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  0%|          | 400/86640 [05:57<8:39:21,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4579084813594818, 'eval_accuracy': 0.8029141104294478, 'eval_runtime': 26.6335, 'eval_samples_per_second': 48.961, 'eval_steps_per_second': 6.12, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 450/86640 [06:41<8:00:06,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3183535635471344, 'eval_accuracy': 0.8573619631901841, 'eval_runtime': 27.2307, 'eval_samples_per_second': 47.887, 'eval_steps_per_second': 5.986, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 500/86640 [07:27<8:23:01,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28294530510902405, 'eval_accuracy': 0.8757668711656442, 'eval_runtime': 28.7131, 'eval_samples_per_second': 45.415, 'eval_steps_per_second': 5.677, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 550/86640 [08:13<8:04:11,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3734060525894165, 'eval_accuracy': 0.8404907975460123, 'eval_runtime': 28.8571, 'eval_samples_per_second': 45.188, 'eval_steps_per_second': 5.649, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 600/86640 [08:30<8:23:48,  2.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3736, 'learning_rate': 9.930747922437674e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  1%|          | 600/86640 [09:00<8:23:48,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29867643117904663, 'eval_accuracy': 0.870398773006135, 'eval_runtime': 29.1901, 'eval_samples_per_second': 44.673, 'eval_steps_per_second': 5.584, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "  1%|          | 650/86640 [09:45<8:40:19,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3124051094055176, 'eval_accuracy': 0.8734662576687117, 'eval_runtime': 27.8346, 'eval_samples_per_second': 46.848, 'eval_steps_per_second': 5.856, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 650/86640 [09:46<21:32:15,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 586.0818, 'train_samples_per_second': 1182.275, 'train_steps_per_second': 147.829, 'train_loss': 0.4591100810124324, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=650, training_loss=0.4591100810124324, metrics={'train_runtime': 586.0818, 'train_samples_per_second': 1182.275, 'train_steps_per_second': 147.829, 'train_loss': 0.4591100810124324, 'epoch': 0.23})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_args = get_training_arguments(default_args)\n",
    "\n",
    "trainer = get_trainer(train_args,dataset,model,early_stopping=3)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:27<00:00,  5.85it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing eval results\n",
      "{'eval_loss': 0.6164497137069702, 'eval_accuracy': 0.6672782874617736, 'eval_runtime': 46.1558, 'eval_samples_per_second': 70.847, 'eval_steps_per_second': 8.861, 'epoch': 0.64}\n"
     ]
    }
   ],
   "source": [
    "write_eval_results(eval_results,output_dir,task,trainer,adapter_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    train_args = {\"label_names\":[\"labels\"],\\n    \"evaluation_strategy\":\"steps\",\\n    \"learning_rate\":1e-4,\\n    \"num_train_epochs\":1,\\n    \"per_device_train_batch_size\":8,\\n    \"per_device_eval_batch_size\":8,\\n    \"eval_steps\":50,\\n    \"logging_steps\":200,\\n    \"output_dir\":\"/eval_results\",\\n    \"overwrite_output_dir\":True,\\n    \"remove_unused_columns\":False,\\n    \"lr_scheduler_type\":\\'linear\\',\\n    \"load_best_model_at_end\":True,\\n    \"metric_for_best_model\" : \"accuracy\",\\n    \"early_stopping_patience\":3,\\n    \"save_total_limit\":5\\n}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for attr_name, attr_value in vars(default_args).items():\n",
    "    print(f\"{attr_name}: {attr_value}\")\"\"\"\n",
    "\"\"\"\n",
    "    train_args = {\"label_names\":[\"labels\"],\n",
    "    \"evaluation_strategy\":\"steps\",\n",
    "    \"learning_rate\":1e-4,\n",
    "    \"num_train_epochs\":1,\n",
    "    \"per_device_train_batch_size\":8,\n",
    "    \"per_device_eval_batch_size\":8,\n",
    "    \"eval_steps\":50,\n",
    "    \"logging_steps\":200,\n",
    "    \"output_dir\":\"/eval_results\",\n",
    "    \"overwrite_output_dir\":True,\n",
    "    \"remove_unused_columns\":False,\n",
    "    \"lr_scheduler_type\":'linear',\n",
    "    \"load_best_model_at_end\":True,\n",
    "    \"metric_for_best_model\" : \"accuracy\",\n",
    "    \"early_stopping_patience\":3,\n",
    "    \"save_total_limit\":5\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c9858cbf84a5da59b0eda444a3a9e74ff602edf6c20b71c559d82c1d8891e69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
