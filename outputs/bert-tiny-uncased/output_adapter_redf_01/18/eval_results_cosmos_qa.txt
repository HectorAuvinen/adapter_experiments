batch size = 32
max length = 512
early stopping patience = 3
training time (seconds) = 1789.57
mh_adapter = False
output_adapter = True
reduction_factor = 0.1
non_linearity = relu
original_ln_before = True
original_ln_after = True
ln_before = False
ln_after = False
init_weights = bert
is_parallel = False
scaling = 1.0
use_gating = False
residual_before_ln = True
adapter_residual_before_ln = False
inv_adapter = None
inv_adapter_reduction_factor = None
cross_adapter = False
leave_out = []
phm_layer = False
phm_dim = 4
factorized_phm_W = True
shared_W_phm = False
shared_phm_rule = True
factorized_phm_rule = False
phm_c_init = normal
phm_init_range = 0.0001
learn_phm = True
hypercomplex_nonlinearity = glorot-uniform
phm_rank = 1
phm_bias = True
eval_loss = 1.2399382591247559
eval_accuracy = 0.4626465661641541
eval_runtime = 8.5027
eval_samples_per_second = 351.063
eval_steps_per_second = 11.055
epoch = 12.0
